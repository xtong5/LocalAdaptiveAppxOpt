\subsection{Computational Cost}

In this part, we investigate the computational cost of our locally adaptive algorithm. Let $n_0$ denote the initial number of intervals. We firstly introduce one new notation $\Ixl$.
\[\Ixl=\left[a+\frac{(j-1)(b-a)2^{-l}}{n_0},a+\frac{j(b-a)2^{-l}}{n_0}\right], j=\left\lceil\frac{(x-a)n_02^l}{b-a}\right\rceil, \ l = \mathbb{N}_0.\]
Let
$\ell(x)$ be defined such that
$I_{x,\ell(x)}$ is the final interval which contains $x$ in the final discretization.
Let
\[\bar{I}_{x,l}=\left[a+\frac{\max(0,j-3)2^{-l}(b-a)}{n_0}, a+ \frac{\min(j+2,2^ln_0)2^{-l}(b-a)}{n_0}\right],
\] with the same $j$ as above denote an interval with five times the length that contains $\Ixl$.

Let
\begin{equation}\label{eqn:defoflx}
L(x) = \min \left\{ l \in \natzero : C_l  \norm[\bar{I}_{x,l}]{f''} \le \varepsilon\right\},
\end{equation}
where
\[\qquad C_l=\fC\left(\frac{3\cdot2^{-l}(b-a)}{n_0}\right) \frac{2^{-2l}(b-a)^2}{8n^2_0}
\]
depends on $n_0$, $\fC$, and $l$, but not on $f$.

We want to show that $\ell(x) \le L(x)$. If not, at some point denote $I_{x,L(x)}$ by $[x_{i-1},x_i]$, this $[x_{i-1},x_i]$ should be cut.
By the algorithm, it is necessary that at least one of the following two conditions must hold. Note that 
\[x_i-x_{i-1}=\frac{2^{-L(x)(b-a)}}{n_0}.\]
\begin{enumerate}
  \item $i \in \mathcal{I} \cap \widetilde{\mathcal{I}}$\\
  There are two different cases in this situation. We firstly investigate $i \in \mathcal{I}_+ \cap \widetilde{\mathcal{I}}$, i.e. 
  $x_{i}-x_{i-1} \ge x_{j}-x_{j-1}, j=i+1,i+2$ and
  \begin{align*}
  \abstol < & \frac{B_+(f,[x_{i-1},x_i])}{8}(x_i-x_{i-1})^2 \\
   \le &\frac{\fC(x_{i+2}-x_{i-1})f[x_{i},x_{i+1},x_{i+2}]}{8}(x_{i}-x_{i-1})^2\\
  %\text{since } x_{i}-x_{i-1} \ge x_{j}-x_{j-1}, j=i+1,i+2 \ \ \
    \le & \fC\left(\frac{3\cdot2^{-L(x)}(b-a)}{n_0}\right) \frac{2^{-2L(x)}(b-a)^2}{8n^2_0}\norm[{[x_{i},x_{i+2}]}]{f''} \\
     \le & C_{L(x)} \norm[\bar{I}_{x,L(x)}]{f''} \le \abstol.
  \end{align*}
  We can also use the similar method to obtain
   \begin{align*}
  \abstol < \frac{B_-(f,[x_{i-1},x_i])}{8}(x_i-x_{i-1})^2  \le 
      C_{L(x)} \norm[\bar{I}_{x,L(x)}]{f''} \le \abstol.
  \end{align*}
  Contradiction.
  \item $i \in \widehat{\mathcal{I}}\cap \widetilde{\mathcal{I}}$\\
  There are four different cases in this situation. We firstly investigate $i \in \widehat{\mathcal{I}}_{+1} \cap \widetilde{\mathcal{I}}$, i.e.
  $x_{i}-x_{i-1} \ge x_{j}-x_{j-1}, j=i-1,i+1$ and
  \begin{align*}
  \abstol \le & \frac{B_+(f,[x_{i-2},x_{i-1}])}{8}(x_{i-1}-x_{i-2})^2 \\ \le &\frac{\fC(x_{i+1}-x_{i-2})f[x_{i-1},x_{i},x_{i+1}]}{8}(x_{i-1}-x_{i-2})^2\\
    \le & \fC\left(\frac{3\cdot2^{-L(x)}(b-a)}{n_0}\right) \frac{2^{-2L(x)}(b-a)^2}{8n^2_0}\norm[{[x_{i-1},x_{i+1}]}]{f''} \\
     \le & C_{L(x)} \norm[\bar{I}_{x,L(x)}]{f''} < \abstol.
  \end{align*}
  We can also get contradiction for other three cases.
\end{enumerate}

Hence, we prove $\ell(x) \le L(x)$. Next we want to investigate $2^{L(x)}$.
$$
2^{L(x)}=2^{\min \left\{ l \in \natzero : C_l  \norm[\bar{I}_{x,l}]{f''} \le \varepsilon\right\}} = \min\left\{2^l: l \in  \natzero, C_l \norm[\bar{I}_{x,l}]{f''} \le \varepsilon\right\}.$$
Denote
\begin{align}\label{mxdef}
M(x) & = \min\left\{2^l:  \fC\left(\frac{3(b-a)}{n_0}\right) \frac{2^{-2l}(b-a)^2}{8n^2_0} \norm[\bar{I}_{x,l}]{f''}  \le \varepsilon,  l \in  \natzero\right\}\nonumber \\
 & = \min\left\{2^l:  2^l \ge \sqrt{\frac{\fC\left(\frac{3 \cdot 2^{-l}(b-a)}{n_0}\right)  (b-a)^2  \norm[\bar{I}_{x,l}]{f''} }{8n^2_0\varepsilon}},  l \in  \natzero\right\}.
\end{align}
We obtain the upper bound on computational cost of Algorithm \texttt{funappx\_g}.

\begin{theorem}\label{thm:cost}
Let $A(f,\varepsilon)$ be the adaptive linear spline defined by Algorithm \textnormal{\texttt{funappx\_g}}, and let $n_0$, and $\varepsilon$ be the inputs and parameters described there. Let $\cc$ be the cone of functions defined in~\eqref{conedef}.
Let $M(x)$ is defined in~\eqref{mxdef}.
Then it follows that Algorithm \textnormal{\texttt{funappx\_g}} is successful for all functions in $\cc$,  i.e.,  $\norm[\infty]{f - S(f, \cdot)} \le \varepsilon$.  Moreover, the cost of this algorithm is bounded above as follows:
$$\cost(S,f,\varepsilon) \le \frac{n_0}{b-a}\int_a^b M(x) dx +1.$$
\end{theorem}

\begin{proof}
For subinterval $I_{x,\ell(x)}$, where $\ell(x)$ is defined as above,
which means Algorithm \texttt{funappx\_g} satisfied error tolerance on $I_{x,\ell(x)}$ with two points.
If we take out the right end point of the subinterval, then the density of the cost on $I_{x,\ell(x)}$ can be considered as
$$\frac{n_0}{2^{-\ell(x)}(b-a)}.$$
Thus, we obtain the cost on whole interval $[a,b]$ should be
$$\cost(S,f,\varepsilon)  = \int_a^b \frac{n_0}{2^{-\ell(x)}(b-a)}dx +1= \frac{n_0}{(b-a)}\int_a^b 2^{\ell(x)}dx +1.
$$
If $L(x)$ is defined in~\eqref{eqn:defoflx}, then we know $\ell(x) \le L(x)$. Therefore we obtain an upper bound
$$\cost(S,f,\varepsilon)  \le \frac{n_0}{(b-a)}\int_a^b 2^{L(x)}dx +1.
$$
As $M(x)=2^{L(x)}$ by the definition~\eqref{mxdef}, we obtain
$$\cost(S,f,\varepsilon)  \le \frac{n_0}{(b-a)}\int_a^b M(x) dx +1.
$$
\end{proof}

From Theorem~\ref{thm:cost}, we know for very small $\varepsilon$,
$l$ tends to $\infty$, $ \norm[\bar{I}_{x,l}]{f''} $ tends to $|f''(x)|$.
Thus we can have
$$ M(x) \lesssim 2\sqrt{\frac{\fC\left(\frac{3 \cdot 2^{-l}(b-a)}{n_0}\right)  (b-a)^2 |f''(x)|}{8n^2_0\varepsilon}}.$$
The upper bound on computational cost tends to
\begin{align*}
\cost(S,f,\varepsilon)  & \lesssim \frac{n_0}{(b-a)}\int_a^b 2\sqrt{\frac{\fC\left(\frac{3 \cdot 2^{-l}(b-a)}{n_0}\right)  (b-a)^2 |f''(x)|}{8n^2_0\varepsilon}} dx +1 \\
& =\sqrt{\frac{\fC\left(\frac{3 \cdot 2^{-l}(b-a)}{n_0}\right)}{2\varepsilon}}\int_a^b \sqrt{|f''(x)|} dx +1\\
& =\sqrt{\frac{\fC\left(\frac{3 \cdot 2^{-l}(b-a)}{n_0}\right)}{2\varepsilon}}\norm[1]{\sqrt{|f''|}} dx +1,
\end{align*}
where $\norm[1]{g}=\int_a^b |g''(x)| dx$.
However, when $\varepsilon$ is not that small, the computational cost does not only depend on $\int_a^b|f''(x)|dx$ but also depends on where and how the peaky parts are located.\\
